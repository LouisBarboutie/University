\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=2.5cm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{hyperref}
\setlength\parindent{0pt}

\title{LogMathsHW1}
\author{Louis-Hendrik Barboutie}
\date{April 2022}

\begin{document}

\maketitle

Let us consider the real valued matrix of parameter $u$
\begin{equation} 
M = \begin{bmatrix}
    1 & 0 & 0 \\
    0 & \cosh(u) & \sinh(u) \\
    0 & \sinh(u) & \cosh(u)
\end{bmatrix}
\quad,\quad u \in \mathbb{R} 
\end{equation} 

For it to be diagonalizable, it has to satisfy the following condition: $\det(M) \neq 0$. Let's check:
\begin{align*}
    \begin{vmatrix}
        1 & 0 & 0 \\ 0 & \cosh(u) & \sinh(u) \\ 0 & \sinh(u) & \cosh(u) \end{vmatrix} &= 1 \cdot (\cosh(u) \cdot \cosh(u) - \sinh(u) \cdot \sinh(u)) \\ 
    &= \cosh^2(u) - \sinh^2(u) \\
    &= 1
\end{align*}

Knowing that $\det(M) \neq 0$, we can go ahead and diagonalize it. We have to find the eigenvalues of M, and for that solve the characeristic polynomial $\det(M-\lambda I) = 0$, where $I$ is the identity matrix, and $\lambda$ the eigenvalue of the equation:
\begin{equation}
    M \Vec{x} = \lambda \Vec{x} \quad,\quad \Vec{x} \in \mathbb{R}^3 
\end{equation}

Let's solve it:
\begin{align*}
    &\det(M-\lambda I) = 0 \\ 
    \Leftrightarrow \quad &\begin{vmatrix} 1 - \lambda & 0 & 0 \\ 0 & \cosh(u) - \lambda & \sinh(u) \\ 0 & \sinh(u) & \cosh(u) - \lambda   \end{vmatrix} = 0 \\
    \Leftrightarrow \quad &(1 - \lambda)[(\cosh(u) - \lambda)^2 - \sinh^2(u)] = 0 \\ 
    \Leftrightarrow \quad &(1 - \lambda)[\cosh^2(u) - 2 \lambda \cosh(u) + \lambda^2 - \sinh^2(u)] = 0 \\
    \Leftrightarrow \quad &(1 - \lambda)[\lambda^2 - 2 \lambda \cosh(u) + 1] = 0
\end{align*}

Polynomials can be factorized by finding their roots. For polynomials of degree 2 of the form $ax^2+bx+c = 0$, we have the formulas:
\begin{equation}
    \Delta = b^2 -4ac \quad,\quad x_{\pm} = \frac{-b \pm \sqrt{\Delta}}{2a}
\end{equation}
The factorized form of the polynomial is then $a(x-x_+)(x-x_-) = 0$.

Plugging in our values, and solving for $\lambda$ we get:
\begin{equation*}
    \Delta = (-2\cosh(u))^2-4 = 4(\cosh^2(u)-1) = 4\sinh^2(u)
\end{equation*} and
\begin{equation*}
    \lambda_{\pm} = \frac{2\cosh(u) \pm \sqrt{4\sinh^2(u)}}{2} = \frac{2\cosh(u) \pm 2\sinh(u)}{2} = \cosh(u) \pm \sinh(u)
\end{equation*}

And finally our factorized characteristic polynomial becomes:
\begin{equation}
    (1 - \lambda)(\lambda - \cosh(u) - \sinh(u))(\lambda - \cosh(u) + \sinh(u)) = 0
\end{equation}

We obtain three different eigenvalues:
\begin{equation}
    \begin{cases}
        \lambda_1 = 1 \\
        \lambda_2 = \cosh(u) + \sinh(u) \\
        \lambda_3 = \cosh(u) - \sinh(u) \\
    \end{cases}
\end{equation}

We can then find th associated diagonalized matrix $D$ to the matrix $M$ with the identity:
\begin{equation}
D = \begin{bmatrix} \lambda_1 & 0 & 0 \\ 0 & \lambda_2 & 0 \\ 0 & 0 & \lambda_3 \end{bmatrix} = \begin{bmatrix} 1 & 0 & 0 \\ 0 & \cosh(u)+\sinh(u) & 0 \\ 0 & 0 & \cosh(u) - \sinh(u) \end{bmatrix} 
\end{equation}

It is not hard to verify, using the Euler formulas, that:
\begin{equation}
    \begin{cases}
        \cosh(u) + \sinh(u) = e^u \\
        \cosh(u) - \sinh(u) = e^{-u}
    \end{cases}
\end{equation}

Therefore we obtain:
\begin{equation}
    D = \begin{bmatrix} 1 & 0 & 0 \\ 0 & e^u & 0 \\0 & 0 & e^{-u} \end{bmatrix}
\end{equation}
Note that we need to have $u \neq 0$, else we have the identity matrix, with infinitely many, trivial eigenvectors.

One can then transform the matrix $M$ into it's diagonal form via a basis change transformation:
\begin{equation}
    M = PDP^{-1}
\end{equation}
Where $P$ is the associated change of basis matrix:
\begin{equation}
    P = \begin{bmatrix}
        | & | & | \\
        v_1 & v_2 & v_3 \\
        | & | & |
    \end{bmatrix}
\end{equation} With $v_1,\ v_2,\ v_3$ the eigenvectors associated to $\lambda_1,\ \lambda_2,\ \lambda_3$. Let's compute them:

Let $\Vec{x} \in \mathbb{R}^3$, $\Vec{x} = (x,y,z)^t$. Then:
\begin{align*}
    &M \Vec{x} = \lambda_1 \Vec{x} \\
    \Leftrightarrow \quad &\begin{cases}
        x = \lambda_1 x \\
        \cosh(u)y + \sinh(u)z = \lambda_1 y \\
        \sinh(u)y + \cosh(u)z = \lambda_1 z
    \end{cases} \\
    \Leftrightarrow \quad &\begin{cases}
        x = x \\
        \cosh(u)y + \sinh(u)z = y \\
        \sinh(u)y + \cosh(u)z = z
    \end{cases} \\
    \Leftrightarrow \quad &\begin{cases}
        x = x \\
        y(\cosh(u) - 1) + z \sinh(u) = 0 \\
        z(\cosh(u) - 1) + y \sinh(u) = 0
    \end{cases} \\
    \Leftrightarrow \quad &\begin{cases}
        x = x \\
        y(\cosh(u) - 1 - \sinh(u)) - z( \cosh(u) - 1 - \sinh(u))  = 0 \\
        z(\cosh(u) - 1) + y \sinh(u) = 0
    \end{cases} \\
    \Leftrightarrow \quad &\begin{cases}
        x = x \\
        y = -z, &\text{since} \ \cosh(u)-\sinh(u)-1 = e^{-u}-1 \neq 0, \ \text{for} \ u \neq 0\\
        z(\cosh(u) - 1 - \sinh(u)) = 0
    \end{cases} \\
    \Leftrightarrow \quad &\begin{cases}
        x = 1, & \text{we can choose this value arbitrarily, might as well take a simple value} \\
        y = 0 \\
        z = 0
    \end{cases} 
\end{align*}

So the first (normalized) eigenvector of $M$ is $v_1 = (1,0,0)^t$.

\begin{align*}
    &M \Vec{x} = \lambda_2 \Vec{x} \\
    \Leftrightarrow \quad &\begin{cases}
        x = \lambda_2 x \\
        \cosh(u)y + \sinh(u)z = \lambda_2 y \\
        \sinh(u)y + \cosh(u)z = \lambda_2 z
    \end{cases} \\
    \Leftrightarrow \quad &\begin{cases}
        x = e^u x \\
        \cosh(u)y + \sinh(u)z = \cosh(u)y + \sinh(u)y \\
        \sinh(u)y + \cosh(u)z = \cosh(u)z + \sinh(u)z
    \end{cases} \\
    \Leftrightarrow \quad &\begin{cases}
        x = 0 \\
        y = z = 1, &\text{we choose this value arbitrarily} \\
        z = 1
    \end{cases} \\
\end{align*}

So the second (normalized) eigenvector of $M$ is $v_2 = \sqrt{2}^{-1}(0,1,1)^t$.

\begin{align*}
    &M \Vec{x} = \lambda_3 \Vec{x} \\
    \Leftrightarrow \quad &\begin{cases}
        x = \lambda_2 x \\
        \cosh(u)y + \sinh(u)z = \lambda_3 y \\
        \sinh(u)y + \cosh(u)z = \lambda_3 z
    \end{cases} \\
    \Leftrightarrow \quad &\begin{cases}
        x = e^{-u} x \\
        \cosh(u)y + \sinh(u)z = \cosh(u)y - \sinh(u)y \\
        \sinh(u)y + \cosh(u)z = \cosh(u)z - \sinh(u)z
    \end{cases} \\
    \Leftrightarrow \quad &\begin{cases}
        x = 0 \\
        y = -z = 1, &\text{we choose this value arbitrarily} \\
        z = -1
    \end{cases} \\
\end{align*}

So the second (normalized) eigenvector of $M$ is $v_2 = \sqrt{2}^{-1}(0,1,-1)^t$.

We can finally write out the matrix $P$:
\begin{equation}
    P = \frac{1}{\sqrt{2}}\begin{bmatrix} \sqrt{2} & 0 & 0 \\ 0 & 1 & 1 \\ 0 & 1 & -1 \end{bmatrix}
\end{equation}  

We can invert this matrix using the standard method:
\begin{align*}
    \left[ \begin{array}{ccc|ccc} \sqrt{2} & 0 & 0 & 1 & 0 & 0  \\ 0 & 1 & 1 & 0 & 1 & 0 \\ 0 & 1 & -1 & 0 & 0 & 1 \end{array} \right]
    &\rightarrow \left[ \begin{array}{ccc|ccc} 1 & 0 & 0 & \frac{1}{\sqrt{2}} & 0 & 0  \\ 0 & 1 & 0 & 0 & \frac{1}{2} & \frac{1}{2} \\ 0 & 1 & -1 & 0 & 0 & 1 \end{array} \right] \\ 
    \left[ \begin{array}{ccc|ccc} 1 & 0 & 0 & \frac{1}{\sqrt{2}} & 0 & 0  \\ 0 & 1 & 0 & 0 & \frac{1}{2} & \frac{1}{2} \\ 0 & 0 & -1 & 0 & -\frac{1}{2} & \frac{1}{2} \end{array} \right]
    &\rightarrow \left[ \begin{array}{ccc|ccc} 1 & 0 & 0 & \frac{1}{\sqrt{2}} & 0 & 0  \\ 0 & 1 & 0 & 0 & \frac{1}{2} & \frac{1}{2} \\ 0 & 0 & 1 & 0 & \frac{1}{2} & -\frac{1}{2} \end{array} \right]
\end{align*}

We now also have the inverse of $P$:
\begin{equation}
    P^{-1} = \frac{\sqrt{2}}{2}\begin{bmatrix} \sqrt{2} & 0 & 0 \\ 0 & 1 & 1 \\ 0 & 1 & -1 \end{bmatrix}
\end{equation}

We note that $P = 2P^{-1}$.

We can finally write out the relation between $M$ and its diagonal form $D$: 
\begin{equation}
    M = P D P^{-1} \Leftrightarrow \begin{bmatrix} 1 & 0 & 0 \\ 0 & \cosh(u) & \sinh(u) \\ 0 & \sinh(u) & \cosh(u) \end{bmatrix} = \frac{1}{2} \begin{bmatrix} \sqrt{2} & 0 & 0 \\ 0 & 1 & 1 \\ 0 & 1 & -1 \end{bmatrix} \begin{bmatrix} 1 & 0 & 0 \\ 0 & e^u & 0 \\ 0 & 0 & e^{-u} \end{bmatrix} \begin{bmatrix} \sqrt{2} & 0 & 0 \\ 0 & 1 & 1 \\ 0 & 1 & -1 \end{bmatrix}
\end{equation}

I checked, and it works btw. Something interesting I found: \href{https://www.youtube.com/watch?v=a3Z7zEc7AXQ}{https://en.wikipedia.org/wiki/Invertible\_matrix}

    \label{tab:my_label}
\begin{table}
    \centering
    \begin{tabular}{c|c}
         &  \\
         & 
    \end{tabular}
    \caption{Caption}
\end{table}
\end{document}
